{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Package Import ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(model):\n    f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n    # training loss and validation loss\n    ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n    ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n\n    # training accuracy and validation accuracy\n    ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n    ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n\n    plt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"markdown","source":"### Load dataset from Keras","metadata":{}},{"cell_type":"code","source":"# import the dataset from keras\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the train set into train set and validation set\nx_train, x_validation, y_train, y_validation = train_test_split(x_train,y_train,test_size=.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AlexNet","metadata":{}},{"cell_type":"code","source":"def process_images(image, label):\n    # Normalize images to have a mean of 0 and standard deviation of 1\n    image = tf.image.per_image_standardization(image)\n    # Resize images from 32x32 to 64x64\n    image = tf.image.resize(image, (64, 64))\n    return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\ntest_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\nvalidation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\nprint(\"Train size:\", train_ds_size)\nprint(\"Test size:\", test_ds_size)\nprint(\"Validation size:\", validation_ds_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = (train_ds\n            # pre-process the image\n            .map(process_images)\n            # shuffle the dataset\n            .shuffle(buffer_size=train_ds_size)\n            # batch dataset\n            .batch(batch_size=32, drop_remainder=True))\n\n# do the same for the test set and the validation set\ntest_ds = (test_ds\n           .map(process_images)\n           .shuffle(buffer_size=train_ds_size)\n           .batch(batch_size=32, drop_remainder=True))\n\nvalidation_ds = (validation_ds\n                 .map(process_images)\n                 .shuffle(buffer_size=train_ds_size)\n                 .batch(batch_size=32, drop_remainder=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model\nalex = keras.models.Sequential([\n    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3)),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(2048,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(2048,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(10,activation='softmax')  \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alex.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\nalex.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alex.fit(train_ds,\n         epochs=50,\n         validation_data=validation_ds,\n         validation_freq=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(alex)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"# encode the labels\ny_train=np_utils.to_categorical(y_train)\ny_validation=np_utils.to_categorical(y_validation)\ny_test=np_utils.to_categorical(y_test)\nprint((x_train.shape,y_train.shape))\nprint((x_validation.shape,y_validation.shape))\nprint((x_test.shape,y_test.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augumentation\ntrain_generator = ImageDataGenerator(rotation_range=2, \n                                    horizontal_flip=True,\n                                    zoom_range=.1 )\n\nval_generator = ImageDataGenerator(rotation_range=2, \n                                    horizontal_flip=True,\n                                    zoom_range=.1)\n\ntest_generator = ImageDataGenerator(rotation_range=2, \n                                    horizontal_flip= True,\n                                    zoom_range=.1)\ntrain_generator.fit(x_train)\nval_generator.fit(x_validation)\ntest_generator.fit(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG-19","metadata":{}},{"cell_type":"code","source":"# change the learning rate if the validation error does not reduce after a set number of epochs\nlr_reducer = ReduceLROnPlateau(monitor='val_acc', # metric to be used\n                       factor=.01, # reduce rate\n                       patience=3, # number of epochs after which if there is no improvement in the val_acc, the learning rate is reduced\n                       min_lr=1e-5) # the minimum learning rate ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the pre-trained model\nvgg = keras.applications.vgg19.VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finish building the model\nvgg19 = keras.models.Sequential()\nvgg19.add(vgg)\nvgg19.add(keras.layers.Flatten())\nvgg19.add(keras.layers.Dense(1024,activation=('relu'),input_dim=512))\nvgg19.add(keras.layers.Dense(512,activation=('relu'))) \nvgg19.add(keras.layers.Dense(256,activation=('relu'))) \nvgg19.add(keras.layers.Dense(128,activation=('relu')))\nvgg19.add(keras.layers.Dense(10,activation=('softmax'))) #This is the classification layer\nvgg19.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use momentum optimizer\nsgd = tf.optimizers.SGD(learning_rate=.001,momentum=.9,nesterov=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\nepochs = 50\nvgg19.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\nvgg19.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n                    epochs=epochs,\n                    steps_per_epoch=x_train.shape[0]//batch_size,\n                    validation_data=val_generator.flow(x_validation,y_validation,batch_size=batch_size),\n                    validation_steps=250,\n                    callbacks=[lr_reducer],verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n# training loss and validation loss\nax[0].plot(vgg19.history.history['loss'],color='b',label='Training Loss')\nax[0].plot(vgg19.history.history['val_loss'],color='r',label='Validation Loss')\n\n# training accuracy and validation accuracy\nax[1].plot(vgg19.history.history['accuracy'],color='b',label='Training  Accuracy')\nax[1].plot(vgg19.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n\nplt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet","metadata":{}},{"cell_type":"markdown","source":"### Define Residual Unit","metadata":{}},{"cell_type":"code","source":"DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n                        padding=\"SAME\", use_bias=False)\n\nclass ResidualUnit(keras.layers.Layer):\n    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n        super().__init__(**kwargs)\n        self.activation = keras.activations.get(activation)\n        self.main_layers = [\n            DefaultConv2D(filters, strides=strides),\n            keras.layers.BatchNormalization(),\n            self.activation,\n            DefaultConv2D(filters),\n            keras.layers.BatchNormalization()]\n        self.skip_layers = []\n        if strides > 1:\n            self.skip_layers = [\n                DefaultConv2D(filters, kernel_size=1, strides=strides),\n                keras.layers.BatchNormalization()]\n\n    def call(self, inputs):\n        Z = inputs\n        for layer in self.main_layers:\n            Z = layer(Z)\n        skip_Z = inputs\n        for layer in self.skip_layers:\n            skip_Z = layer(skip_Z)\n        return self.activation(Z + skip_Z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learning rate scheduler\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0,\n                               patience=5, min_lr=0.5e-6)\n# earlt stopping\nearly_stopper = EarlyStopping(min_delta=0.001, patience=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet-18","metadata":{}},{"cell_type":"code","source":"# build ResNet-18\nrn18 = keras.models.Sequential()\nrn18.add(DefaultConv2D(64, kernel_size=7, strides=2,input_shape=(32,32,3)))\nrn18.add(keras.layers.BatchNormalization())\nrn18.add(keras.layers.Activation(\"relu\"))\nrn18.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\nprev_filters = 64\nfor filters in [64] * 2 + [128] * 2 + [256] * 2 + [512] * 2:\n    strides = 1 if filters == prev_filters else 2\n    rn18.add(ResidualUnit(filters, strides=strides))\n    prev_filters = filters\nrn18.add(keras.layers.GlobalAvgPool2D())\nrn18.add(keras.layers.Flatten())\nrn18.add(keras.layers.Dense(10, activation=\"softmax\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rn18.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# fit the model on the batches generated by the generator.\nrn18.fit_generator(train_generator.flow(x_train, y_train, batch_size=32),\n                   validation_data=val_generator.flow(x_validation,y_validation,batch_size=32),\n                   steps_per_epoch = x_train.shape[0] // 32,\n                   epochs=200,\n                   callbacks=[lr_reducer, early_stopper])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet-34","metadata":{}},{"cell_type":"code","source":"# build resnet-34\nrn34 = keras.models.Sequential()\nrn34.add(DefaultConv2D(64, kernel_size=7, strides=2,\n                        input_shape=[224, 224, 3]))\nrn34.add(keras.layers.BatchNormalization())\nrn34.add(keras.layers.Activation(\"relu\"))\nrn34.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\nprev_filters = 64\nfor filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n    strides = 1 if filters == prev_filters else 2\n    rn34.add(ResidualUnit(filters, strides=strides))\n    prev_filters = filters\nrn34.add(keras.layers.GlobalAvgPool2D())\nrn34.add(keras.layers.Flatten())\nrn34.add(keras.layers.Dense(10, activation=\"softmax\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rn34.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rn34.fit_generator(train_generator.flow(x_train, y_train, batch_size=32),\n                   validation_data=val_generator.flow(x_validation,y_validation,batch_size=32),\n                   steps_per_epoch = x_train.shape[0] // 32,\n                   epochs=200,\n                   callbacks=[lr_reducer, early_stopper])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}